sections_to_merge: ['raw', 'couchdb','train', 'shape', 'tsne','output'],
raw:
{
    csv_data: 'raw/fake_txt_word_vectors.csv'
    users_file: 'raw/fake_txt_users.csv'
},
input:
{
    number_of_examples: 100
    number_for_training: 50
    number_for_validation: 25
    number_for_testing: $input.number_of_examples-$input.number_for_training-$input.number_for_validation
    train_data: 'data/fake_txt_vectors.pkl.gz' # data split into train, validate, and test
    render_data: "data/render_data_0.pkl.gz"
},
shape:
{
    input_vector_length:20
    mid_layer_sizes: [2]
    inner_code_length:1
    #first_layer_type:'poisson'
}
,
train:
{
    method:'cd'
    k:1
    noise_std_dev:0.5
    cost_method: 'squared_diff'
    weights_file: "data/fake_txt_weights.pkl.gz"
    skip_trace_images: False
    train_batch_size:1
    pretrain_lr:0.005
    finetune_lr:0.01
    pretraining_epochs:800
    training_epochs:800
    patience_increase:5
},
tsne:
{
    perplexity: 1 #roughly 'the optimal number of neighbours'
    initial_fit_iterations: 1000
},
output:
{
    coords_file: 'out/fake_txt_coords.csv'
    labels_file: 'out/fake_txt_labels.csv'
    codes_file: 'out/fake_txt_codes.csv'
    density_plot_file: 'trace/fake_txt_map.png'
}
