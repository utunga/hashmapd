sections_to_merge: ['raw', 'couchdb','train', 'shape', 'tsne','output'],
raw:
{
    csv_data: 'raw/train_user_token_counts.csv'
    words_file: 'raw/train_tokens.csv'
    users_file: 'raw/train_users.csv'
},
input:
{
    number_of_examples:200
    number_for_training:100
    number_for_validation:50
    number_for_testing:50 # $input.number_of_examples-$input.number_for_training-$input.number_for_validation
    train_data: 'data/word_vectors_' # data split into train, validate, and test across several files
    render_data: 'data/all_word_vectors.pkl.gz' #data in one numpy array, for purposes of rendering
}, 
shape:
{
    input_vector_length:386
    mid_layer_sizes: [50,12]
    inner_code_length: 3
    first_layer_type:'bernoulli'
},
train:
{
    method:'cd'
    k:1
    noise_std_dev:0.0
    cost_method:'squared_diff'
    weights_file:'out/word_vectors_weights.pkl.gz'
    n_ins: $shape.input_vector_length
    skip_trace_images: False
    train_batch_size:1
    pretrain_lr:0.005
    finetune_lr:0.01
    pretraining_epochs:800
    training_epochs:800
    patience_increase:5
},
tsne:
{
    perplexity: 5 #roughly 'the optimal number of neighbours'
    initial_fit_iterations: 100000
},
output:
{
    coords_file: 'out/coords.csv'
    labels_file: 'out/labels.csv'
    codes_file: 'out/codes.csv'
    density_plot_file: 'density_plot.png'
}
