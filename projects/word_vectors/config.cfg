sections_to_merge: ['raw', 'couchdb','train', 'shape', 'tsne','output'],
raw:
{
    couch_server_url: 'http://127.0.0.1:5984'
    couch_db: 'hashmapd'
    csv_data: 'raw/train_user_token_counts.csv'
    words_file: 'raw/train_tokens.csv'
    users_file: 'raw/train_users.csv'
},
input:
{
    number_of_examples:2992
    number_for_training:1500
    number_for_validation:800
    number_for_testing: $input.number_of_examples-$input.number_for_training-$input.number_for_validation
    train_data: 'data/word_vectors_' # data split into train, validate, and test across several files
    render_data: 'data/all_word_vectors.pkl.gz' #data in one numpy array, for purposes of rendering
}, 
shape:
{
    input_vector_length:200
    mid_layer_sizes: [128]
    inner_code_length: 32
},
train:
{
    method:'pcd'
    k:2
    first_layer_type:'bernoulli'
    noise_std_dev:0.0
    cost:'squared_diff'
    weights_file:'out/word_vectors_weights.pkl.gz'
    n_ins: $shape.input_vector_length
    train_batch_size:10 
    pretraining_epochs:1000 
    training_epochs:300
    skip_trace_during_training: False
    skip_trace_images: False
},
tsne:
{
    perplexity: 3#roughly 'the optimal number of neighbours'
    initial_fit_iterations: 100
},
output:
{
    coords_file: 'out/coords.csv'
    labels_file: 'out/labels.csv'
    codes_file: 'out/codes.csv'
    density_plot_file: 'out/density_plot.png'
}
