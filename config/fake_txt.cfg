
sections_to_merge: ['raw', 'couchdb','train', 'shape', 'tsne','output'],

raw:
{
    raw_data_file: 'data/fake_raw_data.json' 
}
couchdb:
{
    server_url: 'http://127.0.0.1:5984'
    database: 'fake_txt'
}
input:
{
    csv_data: 'data/fake_txt_word_vectors.csv'
    words_file: 'out/fake_words.csv'
    users_file: 'out/fake_users.csv'
    number_of_examples: 21
    number_for_training:21
    number_for_validation:0
    number_for_testing: $input.number_of_examples-$input.number_for_training-$input.number_for_validation
    train_data: 'data/fake_txt_vectors.pkl.gz' # data split into train, validate, and test
    render_data: 'data/render_fake_txt_vectors.pkl.gz' #data in one numpy array, for purposes of rendering
    render_data_has_labels: False
    
},
shape:
{
    input_vector_length: 38 #num pixels per image
    mid_layer_sizes: [10]
    inner_code_length: 4
}
,
train:
{
    weights_file: "data/fake_txt_weights.pkl.gz"
    skip_trace_during_training: True
    skip_trace_images: True
    train_batch_size:2
    pretraining_epochs:500
    training_epochs:100
},
output:
{
    coords_file: 'out/fake_txt_coords.csv'
    labels_file: 'out/fake_txt_labels.csv'
    codes_file: 'out/fake_txt_codes.csv'
}
